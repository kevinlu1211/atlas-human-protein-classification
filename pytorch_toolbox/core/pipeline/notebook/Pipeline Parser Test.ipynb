{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re\n",
    "import os\n",
    "from itertools import chain\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from miniutils.progress_bar import parallel_progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_loader.py\n",
    "class PyTorchToolboxLoader(yaml.SafeLoader):\n",
    "    pass\n",
    "\n",
    "def var_constructor(loader, node):\n",
    "    return Variable(name=node.value)\n",
    "\n",
    "@dataclass\n",
    "class Variable:\n",
    "    name: str\n",
    "        \n",
    "def ref_constructor(loader, node):\n",
    "    ref_node_name_and_output_name = node.value.split(\".\")\n",
    "    assert len(ref_node_name_and_output_name) == 2\n",
    "    ref_node_name, output_name = ref_node_name_and_output_name\n",
    "    return Reference(ref_node_name=ref_node_name, output_name=output_name)\n",
    "\n",
    "@dataclass\n",
    "class Reference:\n",
    "    ref_node_name: str\n",
    "    output_name: str\n",
    "        \n",
    "def replace_config_variables(config, resource_key=\"Resources\", variable_key=\"Variables\"):\n",
    "    config = deepcopy(config)\n",
    "    try:\n",
    "        replaced_resources = replace_variables(config[resource_key], config[variable_key])\n",
    "        config[resource_key] = replaced_resources\n",
    "    except KeyError:\n",
    "        return config\n",
    "    return config\n",
    "\n",
    "def replace_variables(resources, variables):\n",
    "    if isinstance(resources, dict):\n",
    "        for name, resource in resources.items():\n",
    "            resources[name] = replace_variables(resource, variables)\n",
    "    elif isinstance(resources, list):\n",
    "        for i, resource in enumerate(resources):\n",
    "            resources[i] = replace_variables(resource, variables)\n",
    "    elif isinstance(resources, Variable):\n",
    "        resources = variables[resources.name]\n",
    "    else:\n",
    "        return resources\n",
    "    return resources\n",
    "\n",
    "\n",
    "# This tells the loader that when it sees \"!path\" it will pass the value proceeding the !path value into the path constructor\n",
    "PyTorchToolboxLoader.add_constructor('!Var', var_constructor)\n",
    "PyTorchToolboxLoader.add_constructor('!Ref', ref_constructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(Path(\"yaml_loader_test_resource.yml\").open(\"r\"), Loader=PyTorchToolboxLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_config = replace_config_variables(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Variables': {'single_variable': 'hello', 'list_variable': ['foo', 'bar']},\n",
       " 'Resources': {'TestSingleVariableReplacement': {'single_variable': 'hello'},\n",
       "  'TestListVariableReplacement': {'list_variable': ['foo', 'bar']},\n",
       "  'TestVariableInListReplacement': ['hello', ['foo', 'bar']],\n",
       "  'TestVariableInListOfDictionaryReplacement': [{'dict_1': 'hello'},\n",
       "   {'dict_2': ['foo', 'bar']}],\n",
       "  'MockReferenceForTest': {'output': ['some_reference']},\n",
       "  'TestFindReference': {'ref_var': Reference(ref_node_name='MockReferenceForTest', output_name='some_reference')},\n",
       "  'TestFindReferenceInList': [Reference(ref_node_name='MockReferenceForTest', output_name='some_reference')],\n",
       "  'TestFindReferenceInListOfDictionary': {'ref_var_in_list_of_dictionary': [{'key_1': Reference(ref_node_name='MockReferenceForTest', output_name='some_reference')}]}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSingleVariableReplacement\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_references' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41acef0f9c2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Resources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'find_references' is not defined"
     ]
    }
   ],
   "source": [
    "for name, resource in config['Resources'].items():\n",
    "    print(name)\n",
    "    print(find_references(resource))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try on original configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Optional, Dict, Any, Iterator, Iterable, Sequence, Union, Callable, Tuple, List, Any, Collection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def listify(p=None, q=None):\n",
    "    \"Make `p` same length as `q`\"\n",
    "    if p is None:\n",
    "        p = []\n",
    "    elif isinstance(p, str):\n",
    "        p = [p]\n",
    "    elif not isinstance(p, Iterable):\n",
    "        p = [p]\n",
    "    n = q if type(q) == int else len(p) if q is None else len(q)\n",
    "    if len(p) == 1: p = p * n\n",
    "    assert len(p) == n, f'List len mismatch ({len(p)} vs {n})'\n",
    "    return list(p)\n",
    "\n",
    "def load_training_data(root_image_paths, root_label_paths, use_n_samples):\n",
    "    train_df = load_training_data_df(root_image_paths, root_label_paths, use_n_samples)\n",
    "    labels = train_df['Target'].values\n",
    "    labels_one_hot = make_one_hot(labels, n_classes=28)\n",
    "    return np.array(train_df['ImagePath'].values), np.array(labels), np.array(labels_one_hot)\n",
    "\n",
    "def load_training_data_df(root_image_paths, root_label_paths, use_n_samples):\n",
    "    labels_df = load_training_labels(root_label_paths)\n",
    "    labels_df.sort_values([\"Id\"], ascending=[True], inplace=True)\n",
    "    labels_df_sorted_by_id = labels_df\n",
    "\n",
    "    # As some duplicate images were removed, we only use the images that have labels\n",
    "    image_paths = load_training_images(root_image_paths)\n",
    "    image_paths_with_labels = filter_image_paths_with_labels(image_paths, labels_df)\n",
    "\n",
    "    # Sort by ID so that the labels and the image matches up\n",
    "    train_df = labels_df_sorted_by_id\n",
    "    image_paths_sorted_by_id = sorted(image_paths_with_labels, key=lambda path: path.stem)\n",
    "    train_df[\"ImagePath\"] = image_paths_sorted_by_id\n",
    "\n",
    "    if use_n_samples:\n",
    "        train_df = train_df.sample(use_n_samples)\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def load_training_labels(training_labels_path):\n",
    "    labels_df = pd.read_csv(training_labels_path)\n",
    "    labels_df['Target'] = [[int(i) for i in s.split()] for s in labels_df['Target']]\n",
    "    labels_df['TargetTuple'] = [tuple(t) for t in labels_df['Target']]\n",
    "    return labels_df\n",
    "\n",
    "def load_training_images(training_images_path):\n",
    "    image_paths = []\n",
    "    for p in listify(training_images_path):\n",
    "        image_paths.extend(Path(p).glob(\"*\"))\n",
    "    return image_paths\n",
    "\n",
    "def filter_image_paths_with_labels(image_paths, labels_df):\n",
    "    # We use a Counter to filter in O(n) instead of O(n^2) time\n",
    "    image_id_with_labels_lookup = Counter(labels_df['Id'])\n",
    "    image_paths_used_for_training = [Path(p) for p in image_paths if\n",
    "                                     image_id_with_labels_lookup.get(Path(p).stem) is not None]\n",
    "    return np.array(image_paths_used_for_training)\n",
    "\n",
    "def add_number_of_labels_column(train_df):\n",
    "    train_df.sort_values([\"TargetTuple\"], ascending=[True])\n",
    "    label_counts = Counter([tuple(l) for l in train_df['Target'].values])\n",
    "    train_df['Count'] = [label_counts[tuple(l)] for l in train_df['Target']]\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def add_one_hot_labels_index_column(train_df):\n",
    "    target_tuple_to_label = {v: k for k, v in enumerate(train_df['TargetTuple'].unique())}\n",
    "    train_df['OneHotLabelIndex'] = train_df['TargetTuple'].map(lambda x: target_tuple_to_label[x])\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def load_testing_data(root_image_paths, use_n_samples=None):\n",
    "    X = sorted(list(Path(root_image_paths).glob(\"*\")), key=lambda p: p.stem)\n",
    "    if use_n_samples is not None:\n",
    "        X = X[:use_n_samples]\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "def make_one_hot(labels, n_classes=28):\n",
    "    one_hots = []\n",
    "    for label in labels:\n",
    "        one_hot = np.zeros(n_classes)\n",
    "        for label_idx in label:\n",
    "            one_hot[label_idx] = 1\n",
    "        one_hots.append(one_hot.astype(np.float32))\n",
    "    return one_hots\n",
    "\n",
    "def calculate_mean_and_std_for_dataset(some_var, data_paths, shared_state):\n",
    "    print(some_var)\n",
    "    print(shared_state)\n",
    "    flattened_data_paths = list(chain(*data_paths))\n",
    "    means, stds = list(zip(*parallel_progbar(calculate_mean_and_std, flattened_data_paths)))\n",
    "    mean = np.stack(means).mean(axis=0)\n",
    "    std = np.stack(stds).mean(axis=0)\n",
    "    logging.info(f\"Mean of dataset is: {mean}\")\n",
    "    logging.info(f\"Standard deviation of dataset is: {std}\")\n",
    "    return mean, std\n",
    "\n",
    "def calculate_mean_and_std(img_path):\n",
    "    img = open_numpy(img_path, with_image_wrapper=True).tensor\n",
    "    mean = np.mean(img.numpy(), axis=(1, 2))\n",
    "    std = np.std(img.numpy(), axis=(1, 2))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "lookup = {\n",
    "    \"load_testing_data\": load_testing_data,\n",
    "    \"load_training_data\": load_training_data,\n",
    "    \"calculate_mean_and_std_for_dataset\": calculate_mean_and_std_for_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.py\n",
    "from functools import partial\n",
    "import networkx as nx\n",
    "import inspect\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, graph, config):\n",
    "        self.graph = graph\n",
    "        self.config = config\n",
    "        self.shared_state = {\n",
    "            \"config\": deepcopy(config)\n",
    "        }\n",
    "        \n",
    "    @classmethod\n",
    "    def create_graph_from_config(cls, config):\n",
    "        assert config.get(\"Resources\") is not None, \"There is no Resources key in the configuration file\"\n",
    "        graph = nx.DiGraph()\n",
    "        flattened_resources = flatten_dict(config[\"Resources\"])\n",
    "        graph = cls._add_nodes_to_graph(graph, flattened_resources)\n",
    "        graph = cls._add_edges_to_graph(graph)\n",
    "        return cls(graph, config)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _add_nodes_to_graph(graph, resources):\n",
    "        for name, resource in resources.items():\n",
    "            references = find_references(resource)\n",
    "            properties = load_properties_with_default_values(resource[\"properties\"])\n",
    "            node = Node(name=name, references=references, **properties)\n",
    "            graph.add_node(name, node=node)\n",
    "        return graph\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_edges_to_graph(graph):\n",
    "        for name, node_wrapper in graph.nodes(data=True):\n",
    "            node = node_wrapper[\"node\"]\n",
    "            for reference in node.references:\n",
    "                referenced_node_name = reference.ref_node_name\n",
    "                assert referenced_node_name in graph.nodes, f\"The reference: {referenced_node_name} in node: {node.name} does not exist\"\n",
    "                graph.add_edge(referenced_node_name, name)\n",
    "        return graph\n",
    "    \n",
    "    def run(self, to_node=None):\n",
    "        for node_name in nx.algorithms.dag.topological_sort(self.graph):\n",
    "            if to_node == node_name:\n",
    "                break\n",
    "            node = self.graph.nodes(data=True)[node_name][\"node\"]\n",
    "            self.run_node(node)\n",
    "            \n",
    "    def run_node(self, node):\n",
    "        replace_arguments(self.graph, self.shared_state, node)\n",
    "        node.create_output()\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, references, pointer, partial, arguments, output_names):\n",
    "        self.name = name\n",
    "        self.references = references\n",
    "        self.pointer = pointer\n",
    "        self.arguments = arguments\n",
    "        self.output_names = output_names\n",
    "        self.partial = partial\n",
    "        self.reference_replaced_arguments = None\n",
    "        self.output = None\n",
    "        \n",
    "    def create_output(self):\n",
    "        assert self.output_names is not None, f\"There are no outputs defined for node: {self.name}\"\n",
    "        if self.partial:\n",
    "            assert len(self.output_names) == 1, \"If the output of node: {self.name} is partial, then there should be one output, {len(self.output_names)} outputs are found\"\n",
    "            self.output = {self.output_names[0]: partial(self.pointer, **self.reference_replaced_arguments)}\n",
    "        else:\n",
    "            output = self.pointer(**self.reference_replaced_arguments)\n",
    "            iterable_output = [output] if len(self.output_names) == 1 else output\n",
    "            self.output = {output_name: output_value for output_name, output_value in zip(self.output_names, iterable_output)}\n",
    "\n",
    "# graph_construction.py\n",
    "def flatten_dict(d):\n",
    "    flattened = dict()\n",
    "    for resources in d.values():\n",
    "        flattened = {**flattened, **resources}\n",
    "    return flattened\n",
    "\n",
    "def find_references(resource):\n",
    "    references = []\n",
    "    if isinstance(resource, dict):\n",
    "        for _, value in resource.items():\n",
    "            references.extend(find_references(value))\n",
    "    elif isinstance(resource, list):\n",
    "        for value in resource:\n",
    "            references.extend(find_references(value))\n",
    "    elif isinstance(resource, Reference):\n",
    "        references.append(resource)\n",
    "    else:\n",
    "        pass\n",
    "    return references\n",
    "\n",
    "def replace_arguments(graph, shared_state, node):\n",
    "    try:\n",
    "        arguments = node.arguments\n",
    "        needs_shared_state = \"shared_state\" in inspect.signature(node.pointer).parameters\n",
    "        print(needs_shared_state)\n",
    "        if arguments is not None:\n",
    "            reference_replaced_arguments = replace_references(graph, deepcopy(arguments))\n",
    "            if needs_shared_state:\n",
    "                reference_replaced_arguments[\"shared_state\"] = shared_state\n",
    "            node.reference_replaced_arguments = reference_replaced_arguments\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        pass   \n",
    "    \n",
    "\n",
    "\n",
    "def replace_references(graph, arguments):\n",
    "    if isinstance(arguments, dict):\n",
    "        for name, argument in arguments.items():\n",
    "            arguments[name] = replace_references(graph, argument)\n",
    "    elif isinstance(arguments, list):\n",
    "        for i, argument in enumerate(arguments):\n",
    "            arguments[i] = replace_references(graph, argument)\n",
    "    elif isinstance(arguments, Reference):\n",
    "        # reassign name it make the intent clearer\n",
    "        reference = arguments\n",
    "        ref_node = graph.nodes(data=True)[reference.ref_node_name][\"node\"]\n",
    "        ref_node_outputs = ref_node.output\n",
    "        assert ref_node_outputs is not None, f\"Node: {reference.ref_node_name} has no output\"\n",
    "        assert reference.output_name in ref_node_outputs, f\"Node: {reference_node_name} has no output named {reference.output_name}\"\n",
    "        arguments = ref_node_outputs[reference.output_name]\n",
    "    else:\n",
    "        return arguments\n",
    "    return arguments\n",
    "\n",
    "def load_properties_with_default_values(properties):\n",
    "    assert properties[\"pointer\"] in lookup, f\"There is no lookup called: {pointer}\"\n",
    "    return {\n",
    "        \"pointer\": lookup[properties[\"pointer\"]],\n",
    "        \"partial\": properties.get(\"partial\", False),\n",
    "        \"arguments\": properties.get(\"arguments\", {}),\n",
    "        \"output_names\": properties.get(\"output_names\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(Path(\"densenet121_two_input_fc_with_tta_template.yml\").open(\"r\"), Loader=PyTorchToolboxLoader)\n",
    "replaced_config = replace_config_variables(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline.create_graph_from_config(replaced_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_X': array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/00008af0-bad0-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0000a892-bacf-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0008baca-bad7-11e8-b2b9-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0.npy')],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"LoadTestingData\"][\"node\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_X': array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/00008af0-bad0-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0000a892-bacf-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0008baca-bad7-11e8-b2b9-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0.npy')],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"LoadTestingData\"][\"node\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_X': array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/11938_90_D11_1.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/76087_1608_A3_3.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined/44b5e136-bbca-11e8-b2bc-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/62471_1282_H9_2.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/49781_727_B4_1.npy')],\n",
       "       dtype=object),\n",
       " 'train_y': array([list([25, 7, 2]), list([2]), list([25, 17]), list([0]), list([2])],\n",
       "       dtype=object),\n",
       " 'train_y_one_hot': array([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"LoadTrainingData\"][\"node\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_X': array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/00008af0-bad0-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0000a892-bacf-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0008baca-bad7-11e8-b2b9-ac1f6b6435d0.npy'),\n",
       "        PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0.npy')],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"LoadTestingData\"][\"node\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_paths': [array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/11938_90_D11_1.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/76087_1608_A3_3.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined/44b5e136-bbca-11e8-b2bc-ac1f6b6435d0.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/62471_1282_H9_2.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18/49781_727_B4_1.npy')],\n",
       "        dtype=object),\n",
       "  array([PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/00008af0-bad0-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0000a892-bacf-11e8-b2b8-ac1f6b6435d0.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/0008baca-bad7-11e8-b2b9-ac1f6b6435d0.npy'),\n",
       "         PosixPath('/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0.npy')],\n",
       "        dtype=object)],\n",
       " 'shared_state': {'config': {'Variables': {'test_image_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined',\n",
       "    'train_image_paths': ['/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined',\n",
       "     '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18'],\n",
       "    'train_label_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_all_no_dupes.csv'},\n",
       "   'Resources': {'Preprocessing': {'CalculateMeanAndStdForDataset': {'properties': {'pointer': 'calculate_mean_and_std_for_dataset',\n",
       "       'partial': True,\n",
       "       'arguments': {'data_paths': [Reference(ref_node_name='LoadTrainingData', output_name='train_X'),\n",
       "         Reference(ref_node_name='LoadTestingData', output_name='test_X')]},\n",
       "       'output_names': ['calc_fn']}}},\n",
       "    'Data': {'LoadTestingData': {'properties': {'pointer': 'load_testing_data',\n",
       "       'arguments': {'use_n_samples': 5,\n",
       "        'root_image_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined'},\n",
       "       'output_names': ['test_X']}},\n",
       "     'LoadTrainingData': {'properties': {'pointer': 'load_training_data',\n",
       "       'arguments': {'use_n_samples': 5,\n",
       "        'root_image_paths': ['/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined',\n",
       "         '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18'],\n",
       "        'root_label_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_all_no_dupes.csv'},\n",
       "       'output_names': ['train_X', 'train_y', 'train_y_one_hot']}}}}}}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"CalculateMeanAndStdForDataset\"][\"node\"].reference_replaced_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOW\n",
      "{'config': {'Variables': {'test_image_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined', 'train_image_paths': ['/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined', '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18'], 'train_label_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_all_no_dupes.csv'}, 'Resources': {'Preprocessing': {'CalculateMeanAndStdForDataset': {'properties': {'pointer': 'calculate_mean_and_std_for_dataset', 'partial': True, 'arguments': {'data_paths': [Reference(ref_node_name='LoadTrainingData', output_name='train_X'), Reference(ref_node_name='LoadTestingData', output_name='test_X')]}, 'output_names': ['calc_fn']}}}, 'Data': {'LoadTestingData': {'properties': {'pointer': 'load_testing_data', 'arguments': {'use_n_samples': 5, 'root_image_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/test_combined'}, 'output_names': ['test_X']}}, 'LoadTrainingData': {'properties': {'pointer': 'load_training_data', 'arguments': {'use_n_samples': 5, 'root_image_paths': ['/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined', '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_combined_HPAv18'], 'root_label_paths': '/home/kevin/Documents/Kaggle/human-protein-image-classification/data/train_all_no_dupes.csv'}, 'output_names': ['train_X', 'train_y', 'train_y_one_hot']}}}}}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86fae44836946a9bd2510cd55896949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'open_numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-06c6d2672ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CalculateMeanAndStdForDataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"node\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"calc_fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WOW\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-128015c088ef>\u001b[0m in \u001b[0;36mcalculate_mean_and_std_for_dataset\u001b[0;34m(some_var, data_paths, shared_state)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mflattened_data_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparallel_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_mean_and_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_data_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/human-protein-image-classification/lib/python3.7/site-packages/miniutils/progress_bar.py\u001b[0m in \u001b[0;36mparallel_progbar\u001b[0;34m(mapper, iterable, nprocs, starmap, flatmap, shuffle, verbose, verbose_flatmap, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallel_progbar_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_flatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/human-protein-image-classification/lib/python3.7/site-packages/miniutils/progress_bar.py\u001b[0m in \u001b[0;36m_parallel_progbar_launch\u001b[0;34m(mapper, iterable, nprocs, starmap, flatmap, shuffle, verbose, verbose_flatmap, max_cache, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'open_numpy' is not defined"
     ]
    }
   ],
   "source": [
    "p.graph.nodes(data=True)[\"CalculateMeanAndStdForDataset\"][\"node\"].output[\"calc_fn\"](\"WOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

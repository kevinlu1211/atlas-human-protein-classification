{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook shows identifying the duplicated data and calculating image stats of leftover set, and finally saving usable images into a new csv file\n",
    "---\n",
    "[1. Loading training images](#step1)\n",
    "\n",
    "[2. Find duplicates via phash](#step2)\n",
    "\n",
    "[3. Create the deduplicated csv file](#step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter, Iterable\n",
    "from typing import List, Union, Tuple\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from operator import add\n",
    "\n",
    "from miniutils.progress_bar import parallel_progbar, progbar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "from src.data import make_one_hot\n",
    "from src.train_with_template import load_training_data\n",
    "from src.image import get_image_with_id, plot_rgb, plot_rgby, open_numpy\n",
    "from src.data import DataPaths, label_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading training paths<a id='step1'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(DataPaths.TRAIN_COMBINED_IMAGES.glob(\"*\")) + list(DataPaths.TRAIN_COMBINED_IMAGES_HPAv18.glob(\"*\"))\n",
    "image_paths.sort(key=lambda x: x.stem)\n",
    "df = pd.concat([pd.read_csv(DataPaths.TRAIN_LABELS), pd.read_csv(DataPaths.TRAIN_LABELS_HPAv18)])\n",
    "df = df.sort_values(by=['Id'])\n",
    "df['image_paths'] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(df['Id'].values == [p.stem for p in df['image_paths'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find duplicates via phash<a id='step2'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagehash\n",
    "from PIL import Image\n",
    "from miniutils.progress_bar import parallel_progbar, progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phash(data):\n",
    "    name, image_path = data\n",
    "    image = open_numpy(image_path)\n",
    "    phash = imagehash.phash(Image.fromarray(image.px))\n",
    "    return (name, phash.hash.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, image_paths = df['Id'], df['image_paths']\n",
    "names_and_image_paths = zip(names, image_paths)\n",
    "names_and_phashes = parallel_progbar(calculate_phash, names_and_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate phash similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, phashes = zip(*names_and_phashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.75\n",
    "phash_df_data = []\n",
    "for i, (name, phash) in progbar(enumerate(zip(names, phashes))):\n",
    "    similarities = (len(phash) - np.logical_xor(phash, phashes).sum(axis=1))/len(phash)\n",
    "    for similarity, name_of_image_compared in zip(similarities, names):\n",
    "        if similarity > SIMILARITY_THRESHOLD and name != name_of_image_compared:\n",
    "            phash_df_data.append({\n",
    "                \"original_name\": name,\n",
    "                \"compared_image_name\": name_of_image_compared,\n",
    "                \"similarity\": similarity\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the phash similarity df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.DataFrame(phash_df_data)\n",
    "similarity_df.to_csv(\"phash_sim.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv(\"phash_sim.csv\")\n",
    "sorted_similarity_df = similarity_df.sort_values(['similarity'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similarity_df['similarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the images that have a high phash similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples_with_similarity = lambda df, similarity: df['similarity'].map(lambda x: x == similarity)\n",
    "get_samples_with_similarity_above_and_equal = lambda df, similarity: df['similarity'].map(lambda x: x >= similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_samples = sorted_similarity_df[get_samples_with_similarity(sorted_similarity_df, 0.875)]\n",
    "# for i, (name1, name2) in enumerate(zip(df_with_samples['original_name'].values.tolist(),\n",
    "#                                       df_with_samples['compared_image_name'].values.tolist())):\n",
    "#     plot_rgby(get_image_with_id(name1))\n",
    "#     plot_rgby(get_image_with_id(name2))\n",
    "#     plt.show()\n",
    "#     if i == 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of all the images that have a similarity score of 0.93750 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_similarity_df = sorted_similarity_df[get_samples_with_similarity_above_and_equal(sorted_similarity_df, 0.93750)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_similarity_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_names = [name for name in filtered_similarity_df['original_name'].values if \"-\" not in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_names = []\n",
    "for i, (name1, name2) in enumerate(zip(filtered_similarity_df['original_name'].values.tolist(),\n",
    "                                       filtered_similarity_df['compared_image_name'].values.tolist())):\n",
    "    both_samples_are_from_kaggle = \"-\" in name1 and \"-\" in name2\n",
    "    sample_1_is_from_kaggle = \"-\" in name1\n",
    "    sample_2_is_from_kaggle = \"-\" in name2\n",
    "    if both_samples_are_from_kaggle:\n",
    "        filtered_names.append(name1)\n",
    "    elif sample_1_is_from_kaggle:\n",
    "        filtered_names.append(name1)\n",
    "    elif sample_2_is_from_kaggle\n",
    "        filtered_names.append(name2)\n",
    "    else:\n",
    "        filtered_names.append(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filtered_names = list(set(filtered_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_filtered_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the deduplicated csv file<a id='step3'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(DataPaths.TRAIN_LABELS), pd.read_csv(DataPaths.TRAIN_LABELS_HPAv18)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_dupes = df[df['Id'].map(lambda x: x not in filtered_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_dupes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_dupes.to_csv(DataPaths.TRAIN_LABELS_ALL_NO_DUPES, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a helper function to load training data, this is later used to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_one_hot = load_training_data(\n",
    "    root_image_paths=[str(DataPaths.TRAIN_COMBINED_IMAGES),str(DataPaths.TRAIN_COMBINED_IMAGES_HPAv18)],\n",
    "    root_label_paths=str(DataPaths.TRAIN_LABELS_ALL_NO_DUPES),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_one_hot = load_training_data(\n",
    "    root_image_paths=str(DataPaths.TRAIN_COMBINED_IMAGES),\n",
    "    root_label_paths=str(DataPaths.TRAIN_LABELS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rgby(open_numpy(X[0]).px)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
